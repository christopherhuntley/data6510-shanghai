{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Dolan.png\" width=\"180px\" align=\"right\">\n",
    "\n",
    "# **DATA 6510**\n",
    "# **Lesson 3: Advanced SELECT Statements**\n",
    "_Retrieving data from multiple tables._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rHzwUorF5ab"
   },
   "source": [
    "## **Learning Objectives**\n",
    "### **Theory / Be able to explain ...**\n",
    "- The use of implicit joins, explicit joins, and subqueries\n",
    "- The use of numeric surrogate keys instead of text names\n",
    "- Variations of the SQL JOIN operator (natural, equijoin, theta join)\n",
    "- The use of outer joins to work with optional table relationships\n",
    "- Subqueries as SQL expressions\n",
    "\n",
    "### **Skills / Know how to ...**\n",
    "- Use `JOIN` operators to connect data from multiple tables\n",
    "- Write subqueries for common use cases where JOIN is insufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVKAjKlGheMm"
   },
   "source": [
    "---\n",
    "## **BIG PICTURE: Data as a Foreign Language**\n",
    "\n",
    "Language takes on a new meaning when you are learning a second one. Suddenly you become a literalist, paying attention to things like grammar and spelling in way you never would in your native language. You find yourself needing people to speak very, very slowly so you can transliterate what you hearing in real time. Then, slowly, you start to get a more intuitive feel for things. Over time you can go a little faster, filling in the gaps when the grammar and spelling aren't exactly perfect. Eventually, if you stick with it, you can even start to think in the language almost as well as a native speaker. Then, if you are *really* diligent, you start to speak totally unconsciously, sometimes forgetting what language you are speaking. (One way to tell someone is a natively bilingual speaker is when they are in a mixed crowd. If they get their languages crossed, so that they speak exactly the wrong language to each person, then you know the person is natively bilingual. They think in both languages at once.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is with data. We learn about data by working with datasets, learning conventions like data structures and data types, without really thinking about it much. Data is data, or so we think. Then we come across *foreign* data that doesn't obey all the rules we have been taking for granted. It is then that we *really* start to understand how data works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of this was new to the people who developed SQL. The language has been around so long and had to be warped to fit so many use cases that there really isn't much it can't handle *with planning and effort*.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we will consider some of the many ways to combine data from multiple tables in SQL. Sometimes the integration is pretty straightforward. Sometimes it will take some work and perhaps a few carefully crafted subqueries. And, of course, sometimes it just doesn't work and trying to make it work is just futile and potentially risky. Hopefully, by the end of this lesson you will be able to recognize each case and know what to do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5h41XeBBWcK"
   },
   "source": [
    " ---\n",
    "## **Multi-Table `SELECT` Queries**\n",
    "\n",
    "We will explore three different ways to combine data from multiple tables in a single SQL query:\n",
    "- Implicit joins that use relational algebra\n",
    "- Explicit joins that use the JOIN operator\n",
    "- Subqueries that nest *inside* other queries\n",
    "\n",
    "We are again using the baseball database from Lesson 2, summarized below. For full details about the tables and what the columns mean, please consult Sean Lahman's [database documentation](http://www.seanlahman.com/files/database/readme2016.txt).\n",
    "\n",
    "![Lahman 2016 ERD](./img/L2_baseball_stats_schema.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtUFh7tdEYdh"
   },
   "source": [
    "### **Run this boilerplate code before continuing on.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fTBygBpAj2N"
   },
   "outputs": [],
   "source": [
    "# Load %%sql magic\n",
    "!pip install jupysql\n",
    "%load_ext sql\n",
    "%config SqlMagic.displaylimit = None\n",
    "\n",
    "# Standard Imports\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Install the Python to MySQL DBI connector\n",
    "!pip install pymysql\n",
    "\n",
    "%sql mysql+pymysql://buan6510student:buan6510@database-1003.c55qjoeogr2p.us-east-2.rds.amazonaws.com/lahman2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCFhbs0BBTN9"
   },
   "source": [
    "> **Rerun this code as needed to keep your software up to date and database connection fresh.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Implicit Joins**\n",
    "\n",
    "Implicit joins do not have the `JOIN` keyword in them. That the code is performing a join is *implied*.\n",
    "\n",
    "The format of an implicit join is:\n",
    "```sql\n",
    "SELECT *\n",
    "FROM TableA, TableB\n",
    "WHERE TableA.columnX = TableB.columnX\n",
    "```  \n",
    "\n",
    "It looks pretty simple:\n",
    "- List two tables in the `FROM` clause.\n",
    "- In the `WHERE` clause match columns from one table with columns in the other table.\n",
    "\n",
    "In fact, in the earliest versions of SQL implicit joins were the only way to merge data from multiple tables in SQL. However, they come with some potentially serious problems if the `WHERE` clause is not right. The issue is not so much with the `WHERE` clause as with the `FROM` clause. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following query, which omits the `WHERE` clause entirely:\n",
    "```sql\n",
    "SELECT *\n",
    "FROM TableA, TableB\n",
    "```\n",
    "This is a so-called **cross join**, which we will revisit in detail in Lesson 4. A cross join matches each row in the first table (`TableA`) with each row in the second table (`TableB`). The total number of rows in the result is then given by the product of the row counts for the two tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ds6VBsmML8me"
   },
   "source": [
    "Let's try this ourselves. The following code does a cross join of two of the smaller tables in our baseball database:\n",
    "```sql\n",
    "SELECT nameLast, teamid\n",
    "FROM Master, Teams     -- note: draws rows from two tables\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnHQ3bEDujq6"
   },
   "source": [
    "We can easily determine the number of rows in each table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w41Yzv5CiRCI"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- How many players are there?\n",
    "SELECT count(*)\n",
    "FROM Master;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpxQSHInupoo"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- How many teams are there?\n",
    "SELECT count(*)\n",
    "FROM Teams;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idEbsn7Cu9lL"
   },
   "source": [
    "The total number of rows in the cross join would then be 19105 x 2835 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8P9hGpGlvFKM"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT 19105 * 2835;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ324AEAvOqe"
   },
   "source": [
    "That's a little over 54 million rows. And that was with two modestly sized tables! Imagine if one of the tables had a million rows? It would take virtually forever (i.e., a few minutes) for a cross join like that to complete. (Actually a huge cross join query would eventually die, having exhausted all storage and possibly [bricking](https://www.howtogeek.com/126665/htg-explains-what-does-bricking-a-device-mean/) the server, but who really wants that?)\n",
    "\n",
    "While you may be thinking \"But I would never forget the `WHERE` clause. I'm not that careless!\" it is better to avoid the possibility of crashing a server due to a SQL bug.\n",
    "\n",
    "**So, while we include implicit joins here for completeness, they are inherently dangerous and to be avoided whenever possible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Explicit Joins**\n",
    "\n",
    "Explicit joins use the `JOIN` operator to merge tables in the `FROM` clause. They were added to SQL so many years ago to lessen the risk of unintentional cross joins and potentially improve the speed of performing table joins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several kinds of explicit joins, but the most common form is:\n",
    "```sql\n",
    "SELECT *\n",
    "FROM TableA JOIN TableB ON (TableA.columnX = TableB.columnX);\n",
    "```\n",
    "\n",
    "You'll notice that it includes the same basic information as the implicit join (two tables plus a join condition that must be met) except that there is no way to accidentally create a fatal cross join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three kinds of explicit joins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Natural joins**, where the join condition is omitted entirely:\n",
    "  ```sql\n",
    "  SELECT *\n",
    "  FROM Master JOIN Teams;\n",
    "  ```\n",
    "  In this case SQL will automatically match any columns from the two tables that have the same name and data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Equijoins**, where the join condition matches equal values from specific columns:\n",
    "  ```sql\n",
    "  SELECT *\n",
    "  FROM Master JOIN Teams ON (Master.playerID = Batting.playerID);\n",
    "  ```\n",
    "  Note that we use dot notation (from Lesson 1) to disambiguate the `playerID` columns by specifying the table names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Theta joins**, where the join condition is not strict equality:\n",
    "  ```sql\n",
    "  SELECT DISTINCT m1.nameFirst, m1.nameLast\n",
    "  FROM Master as m1 JOIN Master as m2 ON (m1.birthYear > m2.birthYear)\n",
    "  WHERE m2.nameLast = \"Jeter\" and m2.nameFirst =\"Derek\";\n",
    "  ```  \n",
    "    \n",
    "    \n",
    "    Theta joins are most often used when making \"fuzzy\" matches where strict equality won't work. For example, if we had an invoice for an employee's birthday lunch but forgot who it was for then we could look for employees with birthdays within a week of the luncheon:   \n",
    "    \n",
    "    ```sql\n",
    "    SELECT name, employeeID\n",
    "    FROM employees JOIN payables ON (employee.birthday BETWEEN payables.date-7 AND payables.date+7)\n",
    "    WHERE payables.invoiceID = 1234;\n",
    "    ```   \n",
    "    \n",
    "    Notice that we are using the `BETWEEN` comparator to specify the range of dates we want. (Also, we took some liberties with date arithmetic, which can vary a bit from one DBMS vendor to the next. [Here's how it works in MySQL](https://dev.mysql.com/doc/refman/8.0/en/date-and-time-functions.html#function_date-add).)\n",
    "  Here we are joining the Master table to itself (using aliases to disambiguate the tables) and looking for players who are younger than Derek Jeter *without having to know Derek Jeter's birth year*. What makes this a theta join is the condition ```m1.birthYear > m2.birthYear```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpNZGC_bNvHj"
   },
   "source": [
    "\n",
    "\n",
    "#### **Quick Note about Surrogate Keys**\n",
    "\n",
    "In order to make joins work efficiently and avoid surprises (bugs), we generally want short numeric primary keys (usually with ID in the name) that are generated by the database instead of humans. It is just too easy to accidentally assign a duplicate primary key value, so why not just let the system do it for us?  \n",
    "\n",
    "The best practice is to use a **surrogate key** (a.k.a., \"autonumbering\") mechanism for primary key columns. Surrogate keys  generate key values as integers, starting from 1. Each time a row is added to the table the surrogate key value is *incremented* by 1, causing the rows to be numbered in sequential order. The key values are never reused. If we delete a row in the middle of the table, then the surrogate key value is deleted with it and never reused.\n",
    "\n",
    "We will come back to this issue in Lesson 4, when we discuss the many different kinds of keys used in database design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVH3Q0HfjiZ7"
   },
   "source": [
    "### **`JOIN ... ON`**\n",
    "\n",
    "The syntax for a standard `JOIN ... ON` operation is  \n",
    "```JOIN table ON boolean-expression```\n",
    "\n",
    "- In the examples above we use parentheses like `( )` to make the join boolean expression stand out but it is not strictly required. We can just treat anything after the `ON` like a where clause.\n",
    "- The boolean expression used as the join condition should compare a column from the first table (before the `JOIN`) with a column from the second table (after the `JOIN`).\n",
    "- If needed we can join multiple columns at a time using `AND` in the boolean expression.\n",
    "\n",
    "The following query calculates the batting averages of every player on the 1986 Red Sox with at least one at bat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--kJw405iQ8W"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT playerID, Batting.AB, Batting.H, Batting.H/Batting.AB AS `Batting Average`\n",
    "FROM Batting\n",
    "      JOIN Teams ON (Batting.teamID = Teams.teamID AND Batting.yearID = Teams.yearID)\n",
    "WHERE franchID = 'BOS' AND Teams.yearID = 1986 AND Batting.AB>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50-AOba6kyhz"
   },
   "source": [
    "Here's a nicer version of the same resultset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LW-3wG0nkm5z"
   },
   "outputs": [],
   "source": [
    "_.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJ5FM3kbjgEk"
   },
   "source": [
    "### **`JOIN ... USING (...)`**\n",
    "\n",
    "Long `JOIN ... ON` joins are subject to typos, which can trigger errors like \"Unknown column 'nameLas' in 'field list'\" that get old pretty fast. To minimize typing in situations where the column names match exactly (but a natural join won't work) then we can use the following shorthand syntax:  \n",
    "```JOIN table USING (columns)```\n",
    "\n",
    "Any columns listed inside the parentheses (which are not optional) must exist on both tables. Here we repeat the batting average calculation with the simpler `USING` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHxSXVlwpwyU"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT playerID, Batting.AB, Batting.H, Batting.H/Batting.AB AS `Batting Average`\n",
    "FROM Batting\n",
    "      JOIN Teams USING (teamID, yearID)\n",
    "WHERE franchID = 'BOS' AND Teams.yearID = 1986 AND Batting.AB>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6IUVNghEllF"
   },
   "source": [
    "### **`INNER JOIN`, `LEFT JOIN`, and `RIGHT JOIN`**\n",
    "\n",
    "**SQL joins have a *directional* component** that can be useful in certain situations. Every join we have seen so far is an *inner* join, which is the default. Thus, we rarely see `INNER JOIN` used but we can specify if we want to be explicit about it.\n",
    "\n",
    "A so-called ***outer* join** can take on one of two directions:\n",
    "- **Left join:** `TableA LEFT JOIN TableB` includes every row from `TableA` (to the left of the `JOIN`) and only the matching rows from `TableB` (to the right of the join).\n",
    "- **Right join:** `TableA RIGHT JOIN TableB` is the reverse, including every row from `TableB` but only matching rows from `TableA`.\n",
    "\n",
    "> **Heads up:** Some DBMSes like Google BigQuery, Oracle , and SQL Server also support a more general `FULL OUTER JOIN` syntax that combines the left and right joins, allowing every row from both tables to appear at least once. MySQL and SQLite do not support full outer joins, so **we will stick to left and right joins in this course.**\n",
    "\n",
    "Outer joins are often used when we allow NULL values in foreign keys. For example, what if wanted to see the post season batting average of Adam Greenberg, the [most unlucky but plucky MLB player ever](https://www.cnn.com/2012/10/02/sport/baseball-greenberg-second-chance/index.html)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8rGNbDsyCTu"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT playerID, yearID, BattingPost.AB, BattingPost.H, BattingPost.H/BattingPost.AB AS `Batting Average`\n",
    "FROM Master LEFT JOIN BattingPost USING (playerID)\n",
    "WHERE nameLast = 'Greenberg' and nameFirst = 'Adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AijH4UTb84oH"
   },
   "source": [
    "Adam appeared in exactly two games in his MLB career. For a few years between the first appearance and the second, he was the only player in MLB history to have a plate appearance but no at bats! Neither of his MLB games were in the post season playoffs. If we had left off the `LEFT` direction of the join then we would have gotten exactly *nothing* (i.e., zero rows of data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kr01Uap89slO"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT playerID, yearID, BattingPost.AB, BattingPost.H, BattingPost.H/BattingPost.AB AS `Batting Average`\n",
    "FROM Master\n",
    "      JOIN BattingPost USING (playerID)\n",
    "WHERE nameLast = 'Greenberg' and nameFirst = 'Adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnnaT18RC-pg"
   },
   "source": [
    "We would have needed to use `RIGHT JOIN` if we swapped the order of the `Master` and `Batting` tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VazyarMpDHxx"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Swapped table order but kept `LEFT JOIN`\n",
    "SELECT playerID, yearID, BattingPost.AB, BattingPost.H, BattingPost.H/BattingPost.AB AS `Batting Average`\n",
    "FROM BattingPost\n",
    "      LEFT JOIN Master USING (playerID)\n",
    "WHERE nameLast = 'Greenberg' and nameFirst = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCSSZRmhDP4B"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Switched to a `RIGHT JOIN`\n",
    "SELECT playerID, yearID, BattingPost.AB, BattingPost.H, BattingPost.H/BattingPost.AB AS `Batting Average`\n",
    "FROM BattingPost\n",
    "      RIGHT JOIN Master USING (playerID)\n",
    "WHERE nameLast = 'Greenberg' and nameFirst = 'Adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCz1O650EbEM"
   },
   "source": [
    "> **Heads up: This works; however it is generally better to favor `LEFT JOIN` over `RIGHT JOIN`. In fact, SQLite does not allow right joins at all!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9h6a6rTloIy"
   },
   "source": [
    "### **Chained Joins**\n",
    "\n",
    "There are times when just one join is not enough. If we need columns from three or more tables, then we will have to **chain** them together, one at a time, with joins. The following query uses three chained `JOIN` operations to connect four tables.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obcfPFdMTfgV"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT nameLast,nameFirst, Batting.AB, Batting.H, Batting.H/Batting.AB AS `Batting Average`\n",
    "FROM Master\n",
    "  JOIN Batting ON (Master.playerID = Batting.playerID)\n",
    "  JOIN Teams ON (Batting.teamID = Teams.teamID AND Batting.yearID = Teams.yearID)\n",
    "  JOIN TeamsFranchises ON (Teams.franchID = TeamsFranchises.franchID)\n",
    "WHERE franchName like 'Boston Red%' AND Batting.`yearID` = 1986;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn1lJ_KfCrJO"
   },
   "source": [
    "\n",
    "Remarks:\n",
    "- The last two joins were added so we could look up teams by name (`Boston Red%`) instead of the three letter `franchID`.\n",
    "- The order of the `JOIN` operations within the chain matters. We will see exactly *why* in Lesson 4 when we discuss the mathematical underpinnings of the relational database model and again in Lesson 5 when we discuss strong and weak entities.\n",
    "- Even though no columns were returned from the `Teams` table, we needed to include it anyway. Without the `Teams` table there would be no way to connect the `Batting` table with the `TeamFranchise` table. In other words, there are no keys in common to match in an equijoin. Refer to the ERD in Lesson 2 to see why.   \n",
    "- Each `JOIN` is on a separate line with indentation used to indicate that they are in the same `FROM` clause. **Please follow this convention for every chained join you create in this course.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Subqueries**\n",
    "\n",
    "A subquery is an entire `SELECT` query used as an expression inside another query. To convert any query into a query expression, just wrap it in parentheses like this:   \n",
    "```sql\n",
    "(SELECT nameLast FROM Master)\n",
    "```  \n",
    "For short queries it is okay to leave everything on one line but for longer queries it is better to start each clause on a new line:\n",
    "```sql\n",
    "( SELECT nameList\n",
    "  FROM Master)\n",
    "```\n",
    "Notice how the clauses of the subquery are left-aligned (via spaces); they form a solid left vertical line when you read them. That makes it easier to tell when a subquery starts and ends. We want anything with the same indentation block to be in the same subquery. If we embed a subquery inside of another subquery (making the queries three deep), then we indent a little more to the right to keep the alignment clean.\n",
    "\n",
    "Below we consider all the various ways you can use a subquery within a `SELECT` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-vaueOdNwtJ"
   },
   "source": [
    "### **Subqueries in the `SELECT` Clause**\n",
    "\n",
    "When used in the `SELECT` clause a subquery is treated like a calculated column:\n",
    "```sql\n",
    "SELECT (SELECT ...) ...\n",
    "FROM ...\n",
    "```\n",
    "There is an important caveat, however: the subquery must return a single value (i.e., one row and one column). Also, while not required, always use an alias to give the calculated column a name.\n",
    "\n",
    "Most often these sorts of subqueries are used to assemble collections of calculations on otherwise unrelated data. Here we are getting row counts for a couple of tables. The last subquery is useful to check for duplicates. Just compare the `teamCount` with `uniqueTeamCount` to see that there must be some duplicates in the `teamid` column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAGC4T8QTTgF"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT (SELECT count(*) FROM Master) AS playerCount,\n",
    "       (SELECT count(teamid) FROM Teams) AS teamCount,\n",
    "       (SELECT count(DISTINCT teamid) FROM Teams) as uniqueTeamCount;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdAU4AbqTQuV"
   },
   "source": [
    "### **Subqueries in the `FROM` Clause**\n",
    "When used in the `FROM` clause, a subquery acts as a virtual *pseudo*-table, created on the spot within the outer query:\n",
    "```sql\n",
    "SELECT ...\n",
    "FROM (SELECT ...) AS pseudo-table-name ...\n",
    "```\n",
    "Remarks:\n",
    "- This usage is not very common.\n",
    "- The alias is not optional.  \n",
    "- This form is most often used so that the outer query can \"decorate\" the results of the subquery, joining in more data from other tables or performing calculations on the subquery columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnIiicJXcm9A"
   },
   "source": [
    "In the example below, the subquery `subq` is calculating the number of years each player played. The outer query is then \"decorating\" the subquery results with the player names. This is *sometimes* more efficient than using a `GROUP BY` in the outer query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ej-u4P4HZoez"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT nameLast, nameFirst, playerYears\n",
    "FROM (SELECT playerID, count(DISTINCT yearId) AS playerYears FROM Batting GROUP BY playerID) AS subq\n",
    "  JOIN Master USING (playerID)\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGmJRUioXiow"
   },
   "source": [
    "### **Subqueries in the `WHERE` Clause**\n",
    "When used in the `WHERE`, subqueries appear as expressions within the boolean expressions:\n",
    "```sql\n",
    "SELECT ...\n",
    "FROM ...\n",
    "WHERE some-column operator subquery ...\n",
    "```\n",
    "\n",
    "So, for example, if we only wanted baseball players with above average batting averages on the 1986 Red Sox we could try something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ok6OoNZjMst"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT playerID, Batting.AB, Batting.H, Batting.H/Batting.AB AS `BattingAverage`\n",
    "FROM Batting JOIN Teams USING (teamID, yearID)\n",
    "WHERE franchID = 'BOS'\n",
    "  AND Teams.yearID = 1986\n",
    "  AND Batting.H/Batting.AB > (SELECT sum(Batting.H)/sum(Batting.AB) FROM Batting WHERE yearid = 1986)\n",
    "ORDER BY Batting.AB DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVccr44ikifP"
   },
   "source": [
    "Notice that generally the subquery has to return a single value (one row, one column) in order for the comparison to work. We can generalize a little to multiple rows (but one column) for `IN` comparisons, however.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-CrkhrHdyFF"
   },
   "source": [
    "### **Subqueries in the `WITH` Clause**\n",
    "\n",
    "A `WITH` clause (also known as a Common Table Expression) is unusual because it appears _before_ the `SELECT` clause:\n",
    "```sql\n",
    "WITH\n",
    "  subq1 AS (...),\n",
    "  subq2 AS (...)\n",
    "SELECT ...\n",
    "FROM subq1 ...\n",
    "```\n",
    "\n",
    "A `WITH` clause allows us to give subqueries names so they can act like temporary tables within the remainder of the query. In this case the name comes before the `AS` and the subquery in parentheses afterward. We can list as many named subqueries as we need.\n",
    "\n",
    "Why do we need this? As far as SQL itself is concerned, we don't. However, a `WITH` clause can make some queries a lot easier to read and test. Instead of burying the subqueries in the `FROM` or `WHERE` clauses we can write and test them up front *before* writing the rest of the query.\n",
    "\n",
    "> **Heads up:** `WITH` clauses were only recently added to MySQL (in version 8.0) and won't work in the older MySQL versions you may find used in so-called \"legacy\" systems. Even the syntax highlighting here in Jupyter does not yet recognize the `WITH` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hir3aDmyPtJ-"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Determine the MySQL version\n",
    "-- Need at least version 8.0 for `WITH` clauses to work\n",
    "SELECT VERSION()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhLk5RwKP-yP"
   },
   "source": [
    "### **A Note about *Correlated* Subqueries**\n",
    "\n",
    "A correlated subquery is where the subquery uses data from the outer query. They are not very common but there are certain edge cases where they are pretty useful.\n",
    "\n",
    "If, for example, we repeated the \"players with above average batting averages\" query, except this time comparing to the team batting average instead of the league batting average, then we would need to include the teamID in the subquery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxKs6i6gqH7E"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT playerID, Batting.AB, Batting.H, Batting.H/Batting.AB AS `BattingAverage`\n",
    "FROM Batting JOIN Teams USING (teamID, yearID)\n",
    "WHERE franchID = 'BOS'\n",
    "  AND Teams.yearID = 1986\n",
    "  AND Batting.H/Batting.AB > (SELECT sum(Batting.H)/sum(Batting.AB)\n",
    "                              FROM Batting\n",
    "                              WHERE yearid = 1986 and teamID = Teams.teamID) -- Note: teamID is from outer query\n",
    "ORDER BY Batting.AB DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeYAtdRGrMZ3"
   },
   "source": [
    "> **Heads up: correlated subqueries can be very slow to complete. Only use them when you must.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`UNION`, `INTERSECT`, and `EXCEPT` Queries**\n",
    "\n",
    "We conclude our tutorial on SQL `SELECT` queries with a quick introduction to three special \"set theoretic\" operators that, like joins and subqueries, allow us to combine data from multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note that joins and subqueries are inherently column-oriented. If, for example, we use a join to add a second table to our query, we get access to all its columns as well. Similarly, when we add a subquery in the `SELECT` or `FROM` clauses we are adding more columns into the mix.\n",
    "\n",
    "The `UNION`, `INTERSECT` and `EXCEPT` operators are row-oriented. They never add any columns. Instead, they add or subtract rows. We will get into this more in Lesson 4, but the key concept is that **a table is a *set* of rows.** With the `UNION`, `INTERSECT` and `EXCEPT` operators we can add rows or delete rows from a row set but we can't modify the rows themselves. Each row always has the same number of columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Heads up:** SQL operators *never* alter data. Thus the examples below do not change any table data; they apply the operators to generate a new result set, not a table. If we want to *create a new table* then we will need SQL DDL, which is left for another lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NekcmKiCsxQm"
   },
   "source": [
    "We'll take the set operators one at a time.\n",
    "\n",
    "The `UNION` operator adds two `SELECT` queries:\n",
    "```sql\n",
    "SELECT ...\n",
    "UNION\n",
    "SELECT ...\n",
    "```\n",
    "For example, the following query forms the union of the `Batting` table and the `BattingPost` table:\n",
    "```sql\n",
    "SELECT * FROM Batting\n",
    "UNION\n",
    "SELECT * FROM BattingPost\n",
    "```\n",
    "The top and bottom queries have the same number and types of columns, making them **union-compatible**.  While the names of the columns don't have to match, the number of columns has to be the same and the data types of corresponding columns (first column, second column, etc.) have to have the same data types. If the second column in the top query is integer-valued then the second column of the lower query also has to be integer-valued. The column names themselves always come from the top query, ignoring the names in the bottom query.\n",
    "\n",
    "The `INTERSECT` operator syntax is exactly the same as the `UNION` syntax. However, instead of adding rows, it returns only the rows that appear in both the top and the bottom queries.\n",
    "\n",
    "The `EXCEPT` operator also has a top query and a bottom query, both union-compatible with the other. This time, however, `EXCEPT` only returns the rows in the top query that *are not* found in the bottom query. It is like taking the difference between the two tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "www2vN5LTlDo"
   },
   "source": [
    "---\n",
    "## **PRO TIPS: How to write queries correctly the first time, every time**\n",
    "It's pretty easy to tell a novice SQL coder from a seasoned veteran. The novice always starts typing long queries from the top, working through the clauses one at a time until they reach the bottom. Then they run the query and 99% of the time it fails. SQL will give some sort of cryptic error message $-$ nobody knows what they mean half the time $-$ and then the novice spends 45 minutes or so staring at the code trying to spot the error.\n",
    "\n",
    "There are lots of problems with this approach. Here are a few:\n",
    "- Is there really just one bug? SQL will only report the first fatal error it finds. There may be many more bugs to fix before your code works.\n",
    "- Any time spent staring at the screen is not actually producing working code.\n",
    "- Where do you start to fix the error? Sometimes a bug is spread over several lines; each line is \"correct\" but the combination of lines with each other is fatally wrong.\n",
    "- Sometimes you don't get an error message at all. Instead, the query just runs forever, until it bricks the server (and your professor gives you an F for destroying everybody's homework). Or, the query just returns nothing, a result set with zero rows.\n",
    "\n",
    "A seasoned veteran seemingly never makes these kinds of mistakes. Every query seems to work all the time. Your humble professor has gone entire semesters without having a live SQL bug in a class demo. It can be done! It just takes the discipline to follow the *right* process and the courage to tear apart code that doesn't work. No code is sacred. Sometimes you have to break things before you can fix them.\n",
    "\n",
    "Okay, so what is the process?\n",
    "1. Start with the simplest possible query that does pretty much nothing. Run it to make sure that the SQL runtime is working and that you haven't made a trivial mistake like leaving out the second `E` in `SELECT` or forgotten the semicolon at the end.\n",
    "2. Code the most difficult, most likely to fail, part of the query, making minimal changes to the rest of the query so that it will run. Then run it to make sure you didn't mess up.\n",
    "3. Code the next most difficult ...\n",
    "4. Repeat until the query works.\n",
    "\n",
    "Yes, that really is it! Instead of writing a huge query all at once, write in chucks that can be tested and debugged as you go along. You will write *more total lines of SQL code* but each change will be small and easy to get right before moving on.\n",
    "\n",
    "Now let's get more specific:\n",
    "1. **Create a one table  `SELECT * ... LIMIT 10` query.** Which table? How about whichever table is most central to your query. If asking questions about sales transactions then start with whatever table has that.\n",
    "2. **Focus on the `FROM` clause**, joining in any other tables you need. Rerun the query after joining in each table to be sure you haven't borked something. Note: if a table you want doesn't exist, you may need to use a CTE or subquery instead.  \n",
    "3. **Focus on the `WHERE` clause**, crafting the conditions so that the query only returns the relevant rows and no more.\n",
    "4. **Focus on the `GROUP BY` clause (if needed).** This is only needed if you plan to calculate group aggregates (sums, counts, averages, etc.)\n",
    "5. **Focus on the `SELECT` (and `GROUP BY`) clause(s)**, including just the columns you need. If there is a `GROUP BY` clause then be sure to make the table columns consistent with the `SELECT` clause. You can then add whatever aggregates you need (sums, counts, averages, etc.) to the `SELECT`, taking care to give each a meaningful alias.\n",
    "6. **Focus on the `HAVING` and `ORDER BY` columns.** Note that you can put conditions on columns that don't appear in your `SELECT` clause.\n",
    "7. **Remove the `LIMIT` clause (unless it is relevant to your query).**\n",
    "\n",
    "> **Fun fact: SQL actually runs your clauses in *almost* same order as above.**\n",
    "> 1. `WITH` clause to make sure the CTE data is available\n",
    "> 2. `FROM` clause to check the JOINS and subqueries work\n",
    "> 3. `WHERE` clause to restrict the rows being queried\n",
    "> 4. `GROUP BY` clause to establish the context for all aggregates\n",
    "> 5. `HAVING` clause to restrict the groups in the resultset\n",
    "> 6. `SELECT` clause to specify columns and aggregates\n",
    "> 7. `ORDER BY` clause to get the resultset rows in the right order\n",
    "> 8. `LIMIT` clause to restrict the rows in the resultset\n",
    ">\n",
    "> Why? The same reason as we do it: to do as little work as possible. If the query is going to fail, let it fail early before we have used up lots of data access and compute charges.\n",
    "\n",
    "Let's apply this to a fairly complicated like query this one:\n",
    "```sql\n",
    "SELECT nameLast,nameFirst, Batting.AB, Batting.H, Batting.H/Batting.AB AS `Batting Average`\n",
    "FROM Master\n",
    "  JOIN Batting ON (Master.playerID = Batting.playerID)\n",
    "  JOIN Teams ON (Batting.teamID = Teams.teamID AND Batting.yearID = Teams.yearID)\n",
    "  JOIN TeamsFranchises ON (Teams.franchID = TeamsFranchises.franchID)\n",
    "WHERE franchName like 'Boston Red%' AND Batting.`yearID` = 1986;\n",
    "```\n",
    "\n",
    "Even with the code printed out in front of you, if you were to type it in from top to bottom you would almost certainly have a typo or other error in your code. So, let's not even try to do that. Let's apply our process.\n",
    "\n",
    "**Iteration #1. Simplest possible query.**  \n",
    "We'll start with a query that does as little as possible:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvvWySL-CiH-"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM Master\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePHBxJxEC0sw"
   },
   "source": [
    "Great. It works. We didn't forget the `%%sql` magic and we spelled everything correctly. To avoid typos in the column names we used a wildcard. We even used a `LIMIT` clause so that we don't have to wait for it to list 19000 players.\n",
    "\n",
    "**Iteration #2. `FROM` clause.**  \n",
    "For most queries **the hardest thing is the joins**. If even one join doesn't work then you get the dreaded zero row table! Let's try to join in another table. To minimize typing (and typing mistakes) we'll try `JOIN ... USING` instead of `JOIN ... ON` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYMGCSHPDv0o"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Bug!\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Teams USING (playerID)\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiwrX44HD7V5"
   },
   "source": [
    "Ugh, that didn't work. We know the `playerID` is on the `Master` table, so the error message really doesn't make sense. So, we look at the data model again and realize that we don't have enough common keys to join the `Master` and `Teams` tables. Let's try a different join, this time with the `Batting` table using the `playerID`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0T3rWkAEtCP"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFWT__7xEw-X"
   },
   "source": [
    "That worked! Hooray! So let's tack on another join that gets us closer to the `TeamFranchise` table. Consulting the ER Diagram, this time it's the `Teams` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNoGLTrausrt"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Bug!\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Teams USING (teamID)\n",
    "  JOIN Batting USING (playerID)\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZptJcynWj18"
   },
   "source": [
    "Hmmm. Why isn't `teamID` known? It is on the `Teams` table, right? Oh yeah, the order of the joins in the chain matters. Each join adds columns to the query that we can use to join in more tables. However, if the required foreign key (teamID) has not been added yet then we cannot use it to join in the `Teams` table. Let's swap the joins and see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YbSxLhzFLUv"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- still buggy!\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID)\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH5WLTfoFcck"
   },
   "source": [
    "It ran but there seems to be a problem. It keeps repeating some teams over and over again for the same player. Again, after consulting the data model, we see that `Batting` has a `yearID` column, as does the `Teams` table. Aha! Each season is treated as a new team! The 1905 Centenials are a different team from the 1906 Centenials, etc. This means that leaving `yearID` out of our join condition created a cross join. Oops. If we had not had a `LIMIT` clause then we might have blown up AWS! (Not really. But it might been expensive.) So let's add `yearID` to the join conditions before we get too carried away with ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "MCVhf8PIGhaS",
    "outputId": "8c59c037-f113-4d6a-edbb-4a436e693dc9"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID) -- fixed\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb7W4E4UGrEH"
   },
   "source": [
    "That's better. Now we get back the same rows but with more columns. Okay, now let's add in the final join to the `TeamsFranchises` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5d0r7fZHVqi"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Bug!\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID)\n",
    "  JOIN TeamsFranchises USING (teamID)\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yw0VAd8sIcJM"
   },
   "source": [
    "Oops. Since everything worked just fine before the last join, the bug is in the code we just added. After consulting the data model again, we see that `franchID` appears on both the `Teams` and `TeamsFranchises` tables. We'll join using that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xa9QBIpI7Xf"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID)\n",
    "  JOIN TeamsFranchises USING (franchID)\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7CnWqPHJAEZ"
   },
   "source": [
    "Looks good so far! Now that we have all the data columns we'll need, we can decorate our code with the final details.\n",
    "\n",
    "**Iteration #3: `WHERE` Clause**  \n",
    "Let's start with the `WHERE` clause, which if we get right will allow us to cut out the `LIMIT` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPiAMpY5JY2y"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Bug!\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID)\n",
    "  JOIN TeamsFranchises USING (franchID)\n",
    "WHERE yearID = 1986 AND frachName LIKE 'Boston Red%'\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxtOvLdMKNcO"
   },
   "source": [
    "Oops. Another typo, This time it's easy to catch because the error message tells us where it is. We left out the `n` in `franchName`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LT10uZwqKkEb"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID)\n",
    "  JOIN TeamsFranchises USING (franchID)\n",
    "WHERE yearID = 1986 AND franchName LIKE 'Boston Red%'\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0-2WLhnKxz0"
   },
   "source": [
    "So far, so good. Each player is on Boston's roster, the year is 1986, and there are no duplicates. Let's try taking off the `LIMIT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EepXBecQLBYH"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID)\n",
    "  JOIN TeamsFranchises USING (franchID)\n",
    "WHERE yearID = 1986 AND franchName LIKE 'Boston Red%';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LYOP3BzLGRw"
   },
   "source": [
    "**Iteration #4: SELECT Clause**.\n",
    "Great! That gives us all the players and their stats but really, that's way too many columns. It's time to replace the wildcard with the columns we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRiusz8QLd1L"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT nameLast,nameFirst, Batting.AB, Batting.H\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID)\n",
    "  JOIN TeamsFranchises USING (franchID)\n",
    "WHERE yearID = 1986 AND franchName LIKE 'Boston Red%';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytpX4LJaLn2c"
   },
   "source": [
    "Okay now for the final step. We need to calculate the batting average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRzA_8XeLlt8"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT nameLast,nameFirst, Batting.AB, Batting.H, coalesce(Batting.H/Batting.AB,'N/A') AS `Batting Average`\n",
    "FROM Master\n",
    "  JOIN Batting USING (playerID)\n",
    "  JOIN Teams USING (teamID, yearID)\n",
    "  JOIN TeamsFranchises USING (franchID)\n",
    "WHERE yearID = 1986 AND franchName LIKE 'Boston Red%';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSaYAbG9L876"
   },
   "source": [
    "**Iteration #5. Finishing touches**.\n",
    "That looks great. It could look a little nicer. Let's use pandas to make it pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X77pBd1LMHWY"
   },
   "outputs": [],
   "source": [
    "_.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGZdlIUPNhpC"
   },
   "source": [
    "While it may have taken you a while to follow along with the example, in real time the coding took about 2 minutes. You'll get plenty of practice with this stuff in the homeworks. In the meantime, just follow the process. It really works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f65_eey7BvoV"
   },
   "source": [
    "---\n",
    "## **Tech Spotlight: Google BigQuery and GCP**\n",
    "\n",
    "> **Heads up:** Google BigQuery is not (currently?) accessible in China. We will be using it here as an example of how serverless cloud databases work. If you would like to recreate what you see here, Microsoft (Azure) and Amazon (AWS) have competing products with equivalent features.\n",
    "\n",
    "BigQuery is a popular data hosting service offered as part of the Google Cloud Platform (GCP).\n",
    ">What is BigQuery?\n",
    ">\n",
    ">Storing and querying massive datasets can be time consuming and expensive without the right hardware and infrastructure. BigQuery is an enterprise data warehouse that solves this problem by enabling super-fast SQL queries using the processing power of Google's infrastructure. Simply move your data into BigQuery and let us handle the hard work. You can control access to both the project and your data based on your business needs, such as giving others the ability to view or query your data.\n",
    "\n",
    "While BigQuery has been around for about a decade now (under various brands), it has recently gained a lot of interest with data scientists working with massive datasets. \n",
    "\n",
    "BigQuery is optimized for analytical processing:\n",
    "- All data for a given query is kept in a single table (i.e., no joins)\n",
    "- The data is loaded once and rarely modified\n",
    "- Each row may comprise numerous columns of numerical statistics (facts) with accompanying contextual columns (dimensions)\n",
    "\n",
    "Since the data is somewhat static, there is no need for most of the integrity protections provided by traditional databases. In fact, data redundancy and denormalization (Lessons 4 and 5) are desired in such cases. It makes the job of the analyst easier because *every query* is pretty much the same, either a simple sampling or rows or perhaps a PivotTable-like aggregation like we learned in Lesson 2.\n",
    "\n",
    "Let's take a quick tour and then do a few queries. We'll use the *full* play-by-play dataset from the NBA Boxscore assignment. That's every play in every game since 2004, all 17 million of them.\n",
    "\n",
    "\n",
    "### **Data by the Bucket**\n",
    "The dataset is way too big to work with in a single file. It also never changes so there is little need to keep a copy on your hard disk. Cloud providers like Google, Amazon, etc. provide cloud storage for just this sort of thing.\n",
    "\n",
    "Google Cloud Platform (GCP) stores data in buckets, priced out at a few cents per gigabyte. Here are the files we will be working with:\n",
    "\n",
    "![GCP Buckets](./img/L3_GCP_Buckets.png)\n",
    "\n",
    "A few remarks:\n",
    "- GCP bundles services by the *project* so that teams can work out data access permissions. Files shown are for the `NBA Lineup Facts` project.\n",
    "- The bucket name is `nba_lineup_facts`. There can be multiple buckets per project.\n",
    "- The data files are pretty tame, with the biggest one at just over 300 megabytes. The `play_facts` folder, however, has a 300-400 megabyte file for each season.\n",
    "- All data is stored in CSV format, though we can also use MySQL dump files (i.e., SQL code) if we wanted it to load faster into BigQuery.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Qh9gcjHGUTf"
   },
   "source": [
    "### **Database as Dataset Container**\n",
    "Since a given database may be split into many pieces (through a process called *partitioning*), GCP refers to them as *datasets*. A dataset, in turn, is a collection of BigQuery tables. Below we see the columns of the `play_facts_all` table that we will use for our queries.\n",
    "\n",
    "![GCP data explorer](./img/L3_GCP_data_explorer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXaMugcLKOxt"
   },
   "source": [
    "The data for a given table is loaded from one or more files. If they are small files then we can just upload them. However, for our database they are loaded from cloud storage.\n",
    "\n",
    "![GCP Create Table](./img/L3_GCP_create_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MS5cjOI5cG6l"
   },
   "source": [
    ">For those who are wondering, Google also supports traditional transaction processing with Google Cloud SQL. Thus, the GCP software adheres to the three tiered architecture we learned in Lesson 1:\n",
    ">- Presentation: the GCP web interface (SQL) with export to Google Looker Studio (visualization)\n",
    ">- Logic: the various cloud services that make up the GCP\n",
    ">- Data: A BigQuery or Cloud SQL instance running in the cloud ... somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar0N_4lNLECD"
   },
   "source": [
    "### **BigQuery SQL Workspace**\n",
    "\n",
    "BigQuery provides its own query tool, which looks a lot like just about any other. You can use it to compose queries, run them, and (optionally) save the results to a table.\n",
    "\n",
    "![GCP Query Tool](./img/L3_GCP_query_tool.png)\n",
    "\n",
    "Remarks:\n",
    "- The query aggregates all of the play-by-play data so that we can compare the performance of NBA lineups (i.e., groups of 5 players) across seasons.\n",
    "- Table names in BigQuery (like `nba-lineup-facts.lineup_facts.play_facts_all`) always use dot notation; the format is  `project.dataset.table`.\n",
    "- The query took 3.3 seconds to run. The same calculation took a few *minutes* in pandas, with results 'rolled up' one season at a time.\n",
    "- After running the query the results were saved as new table called `lineups_w_200mins`.\n",
    "\n",
    "**While the query tool is nice for data that never leaves the Google Cloud, it can also be accessed directly from Jupyter notebooks. We will omit that part here, however.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now show a few queries as examples. As has by now become customary, we will phrase each query as a question, with the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0wtY8DmSBQS"
   },
   "source": [
    "#### **Query 1. How many rows are there in the `play_facts_all` table?**\n",
    "\n",
    "```sql\n",
    "SELECT COUNT(*) as total_rows\n",
    "FROM `nba-lineup-facts.lineup_facts.play_facts_all`;\n",
    "```\n",
    "\n",
    "> Result: \n",
    "\n",
    "| total rows |\n",
    "| --- |\n",
    "| 16986388 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAYG595zUq2U"
   },
   "source": [
    "> That's a lot of rows! Imagine trying to do that with MS Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query 2. Which lineups played the most total minutes together in a season?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDrZX_YQT_IU"
   },
   "source": [
    "```sql\n",
    "SELECT *\n",
    "FROM `nba-lineup-facts.lineup_facts.lineups_w_200mins`\n",
    "ORDER BY minutes DESC\n",
    "LIMIT 10;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| year | team |lineup| minutes | plus_minus_36m |\n",
    "| ---  | ---  | ---  | ---     | ---            |\n",
    "| 2006 | DET |['Ben Wallace', 'Chauncey Billups', 'Rasheed W...| 2051.433333 | 8.300538 |\n",
    "| 2005| DET|['Ben Wallace', 'Chauncey Billups', 'Rasheed W...|1906.866667|6.418907 |\n",
    "| 2014|IND|['David West', 'George Hill', 'Lance Stephenso...|1860.016667|6.464458 |\n",
    "| 2013|IND|['David West', 'George Hill', 'Lance Stephenso...|1628.316667|9.219337 |\n",
    "| 2014|POR|['Damian Lillard', 'LaMarcus Aldridge', 'Nicol...|1615.866667|4.700883 |\n",
    "| 2017|WAS|['Bradley Beal', 'John Wall', 'Marcin Gortat',...|1595.083333|7.831566 |\n",
    "| 2010|BOS|['Kendrick Perkins', 'Kevin Garnett', 'Paul Pi...|1535.333333|8.441164 |\n",
    "| 2005|PHX|[\"Amar'e Stoudemire\", 'Joe Johnson', 'Quentin ...|1520.166667|11.414538 |\n",
    "| 2008|BOS|['Kendrick Perkins', 'Kevin Garnett', 'Paul Pi...|1494.800000|11.824993 |\n",
    "| 2010|MEM|['Marc Gasol', 'Mike Conley', 'O.J. Mayo', 'Ru...|1468.333333|4.903519 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Basketball aficionados will note that the top two lineups (rows 0 and 1) were from the great Detroit Pistons teams from the early 2000s. They were kind of famous for playing their starting lineups for most of the game. Why? Because they won a lot of games that way. However, the \"7 seconds or less\" Phoenix Suns (row 7) from the same era actually won games by bigger margins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query 3. Which lineups were the most efficient (i.e., had the best `plus_minus_36m`)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G94MKcKWOGu"
   },
   "source": [
    "```sql\n",
    "SELECT *\n",
    "FROM `nba-lineup-facts.lineup_facts.lineups_w_200mins`\n",
    "ORDER BY plus_minus_36m DESC\n",
    "LIMIT 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| year | team |lineup |minutes|plus_minus_36m |\n",
    "| ---  | ---  | ---   | ---   | ---           |\n",
    "|2011|DAL|['Dirk Nowitzki', 'Jason Kidd', 'Jason Terry',...|349.283333|21.541251|\n",
    "|2018|UTA|['Donovan Mitchell', 'Jae Crowder', 'Joe Ingle...|212.900000|21.136684|\n",
    "|2020|OKC|['Chris Paul', 'Danilo Gallinari', 'Dennis Sch...|221.866667|19.471154|\n",
    "|2008|LAL|['Derek Fisher', 'Kobe Bryant', 'Lamar Odom', ...|226.550000|19.068638|\n",
    "|2017|GSW|['Andre Iguodala', 'Draymond Green', 'Kevin Du...|287.583333|18.651985|\n",
    "|2016|GSW|['Andre Iguodala', 'Andrew Bogut', 'Draymond G...|234.483333|17.962897|\n",
    "|2019|PHI|['Ben Simmons', 'JJ Redick', 'Jimmy Butler', '...|333.600000|17.913669|\n",
    "|2016|CLE|['J.R. Smith', 'Kevin Love', 'LeBron James', '...|205.950000|17.829570|\n",
    "|2016|GSW|['Andre Iguodala', 'Draymond Green', 'Harrison...|295.766667|17.649048|\n",
    "|2009|ORL|['Courtney Lee', 'Dwight Howard', 'Hedo Turkog...|256.300000|17.417089|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we see the classic \"death\" lineups from the Golden State Warriors and others. They won games through pure efficiency. These lineups were among the best in the league on offense *and* defense. While many argued that the Golden State lineups were unfair, it is noteworthy that 4 linueps were actually even better, and only one of them won a championship. The team with the top lineup, the 2011 Dallas Mavericks, were incredibly underrated, with their win over LeBron James and the rest of the Heatles for the championship framed as an *upset*. Not really. They literally had the most efficient lineup in history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query 4. Speaking of LeBron James, how did his lineups do over the years?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDlH9Z9OYC9k",
    "tags": []
   },
   "source": [
    "```sql\n",
    "SELECT *\n",
    "FROM `nba-lineup-facts.lineup_facts.lineups_w_200mins`\n",
    "WHERE lineup like '%LeBron James%'\n",
    "ORDER BY plus_minus_36m DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| year|team|lineup|minutes|plus_minus_36m|\n",
    "| ---  | ---  | ---   | ---   | ---           |\n",
    "|2016|CLE|['J.R. Smith', 'Kevin Love', 'LeBron James', '...|205.950000|17.829570|\n",
    "|2015|CLE|['J.R. Smith', 'Kevin Love', 'Kyrie Irving', '...|527.283333|15.361760|\n",
    "|2011|MIA|['Chris Bosh', 'Dwyane Wade', 'Joel Anthony', ...|240.883333|13.450495|\n",
    "|2013|MIA|['Chris Andersen', 'LeBron James', 'Norris Col...|202.716667|11.898380|\n",
    "|2009|CLE|['Ben Wallace', 'Delonte West', 'LeBron James'...|495.100000|11.706726|\n",
    "|2013|MIA|['Chris Bosh', 'Dwyane Wade', 'LeBron James', ...|332.366667|11.481296|\n",
    "|2016|CLE|['J.R. Smith', 'Kevin Love', 'Kyrie Irving', '...|835.216667|10.430826|\n",
    "|2009|CLE|['Anderson Varejao', 'Delonte West', 'LeBron J...|746.166667|9.938798|\n",
    "|2020|LAL|['Anthony Davis', 'Avery Bradley', 'Danny Gree...|387.950000|9.279546|\n",
    "|2011|MIA|['Chris Bosh', 'Dwyane Wade', 'Erick Dampier',...|268.083333|8.594343|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we see:\n",
    "> - the 2016 Cleveland Cavaliers lineup that upset the Golden State Warriors for the title, \n",
    "> - a slightly less efficient lineup from 2015 that lost to the Warriors, \n",
    "> - James's Miami teams (2011, 2013), and \n",
    "> - then a lot of good but not historically great lineups. \n",
    "> \n",
    "> That LeBron James has won so many titles is truly remarkable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5ls2ggPZdsv"
   },
   "source": [
    "### **Now the Money Shot ...**\n",
    "\n",
    "The above queries were not accidental. They were used to create the scatter plot below entirely in the cloud.\n",
    "- Each dot represents a lineup with at least 200 minutes played. There are almost 900 of them.\n",
    "- The lineups to the far right, at the tip of the arrowhead, are the ones in Query 2.\n",
    "- The big gold dots represent the famous Golden State death lineups. Those are (mostly) listed in Query 3.\n",
    "- The smaller red dots are lineups with LeBron James, which we uncovered in Query 4.  \n",
    "- The blue line at the top (called the tradeoff curve) can be found by rerunning Query 3 over and over again with different minute thresholds (200+ minutes, 350+ minutes, 660+ minutes, etc.). Each lineup on that curve could be said to be the best in history! Or at least since 2004.\n",
    "\n",
    "![nba lineup tradoff](./img/L3_nba_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teOOkEWPAlMs"
   },
   "source": [
    "> **For those of you who aren't sports fans, take heart that is the last of the sports examples for a while. How about movies instead?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVL7n_Rys_95"
   },
   "source": [
    "## **Congratulations! You've made it to the end of Lesson 3.**\n",
    "\n",
    "You now know pretty much everything you need to know about `SELECT` queries. If there is anything else you need to know, then a least you have a solid foundation on which to build.\n",
    "\n",
    "The next quiz will test your understanding of the relevant theory and your ability to write short `SELECT` queries *without the ability to run them in Jupyter*."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNk2vAi4TA3CY7K9Cze/BSu",
   "include_colab_link": true,
   "mount_file_id": "11MBPducEj0HgT0u-nrCE60AvHJQnPR3y",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
